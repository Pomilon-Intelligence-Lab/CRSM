# **The Continuous Reasoning State Model (CRSM): An Open-Source Blueprint for Proactive and Low-Latency SOTA AI Architectures**

> **Note:** This document is the original research output generated by **Gemini 2.5 Flash (Deep Research)** in response to the author's initial prompt. It serves as the foundational blueprint for the project.

## **I. Executive Summary: The Need for Architectural Redefinition**

The remarkable ascent of modern Large Language Models (LLMs), primarily built upon the Transformer architecture, has been based on sequential token prediction. However, continued scaling efforts are encountering fundamental limits related to latency, computational cost, and genuine high-level planning. These persistent limitations necessitate a paradigm shift toward bio-inspired, dynamical systems that integrate continuous internal processing with explicit deliberation.

The research indicates that the existing high latency is symptomatic of a deeper architectural flaw: the inability of sequential token prediction to support robust lookahead planning.1 To move beyond this structural constraint, the proposed Continuous Reasoning State Model (CRSM) is designed as a hybrid architecture. This model integrates the computational efficiency and continuous latent representation of State Space Models (SSMs), particularly the Mamba architecture, with the structural planning capability of classical AI algorithms, such as Tree Search. The CRSM establishes an "always-on" internal reasoning component that operates in parallel, allowing for low-latency output generation even while engaging in complex, multi-step planning. This fundamental redefinition is the essential prerequisite for developing the next generation of scalable, adaptive, and autonomous artificial intelligence systems.

## **II. The Fundamental Constraints of Next-Token Prediction**

A rigorous analysis of current generative models reveals inherent architectural weaknesses that constrain performance in complex, multi-step reasoning tasks, providing the justification for seeking alternatives to the pure autoregressive Transformer paradigm.

### **A. Autoregressive Bias and the Planning Deficit in Transformers**

A primary vulnerability of current LLMs stems from the methodology of standard autoregressive training, often referred to as "teacher-forcing." This training approach supervises the prediction of the next token based on the *true* preceding sequence provided by the training data, rather than the sequence *generated by the model* itself.2 This results in a critical structural flaw known as the "Clever Hans" cheat.

In tasks that require implicit planning or "lookahead," the model relies on the correct, predetermined sequence for later tokens, fundamentally losing the opportunity to learn how to plan for those subsequent tokens.1 Consequently, the initial steps in a complex solution sequence—for example, mapping the input to the first vertex in a graph ($v1$)—become exceedingly difficult to learn because the model has not developed the comprehensive ability to consider the entire solution beforehand.1 This failure in early-stage planning confirms that the issue is not merely a scaling problem but an incompatibility between the next-token prediction objective function and the desired cognitive skill of strategic planning. Furthermore, regardless of the availability of computational resources, the slight probability of error inherent in next-token prediction at each step accumulates exponentially over time, severely limiting the reliability and practical generalization capability of these models in long-form, complex compositional tasks.2

### **B. Latency, Memory Overhead, and the Context Window Dilemma**

For Transformer models to maintain reasoning coherence in complex tasks, they rely heavily on large context windows.3 This reliance introduces massive memory overhead and significant computational constraints, directly limiting practical deployment scenarios. The computational cost scales with the length of the sequence, making the processing of extensive contexts a foundational bottleneck.4

Historically, efficiency gains were achieved by migrating from character-level modeling to subword tokenization, which increased the semantic bandwidth of each predictive unit.4 While successful, the argument is that this reliance on discrete token representation has reached a fundamental limit, constraining further advancements in efficiency.4 This suggests that incremental improvements to the Transformer architecture will inevitably encounter a reasoning ceiling. The pursuit of the next magnitude of efficiency and performance must therefore shift toward continuous modeling techniques.

### **C. The Call for Implicit Reasoning and Continuous Representation**

Existing research focused on implicit reasoning within large, pretrained LLMs often operates in an uncontrolled environment where the training data is opaque. This transparency deficit makes it challenging for researchers to definitively distinguish between genuine, generalized reasoning and simple memorization of training examples.5 The CRSM architecture must explicitly be designed to force and prove genuine reasoning through its internal mechanics.

The domain of complex dynamical systems—systems that evolve over space and time, such as those studied in fluid mechanics or neuroscience—are common subjects in science and engineering.6 However, deep learning systems based on discrete token processing have shown limitations in their ability to process and reason about real-time dynamics across a wide range of spatial and temporal scales.6 To address this, the architectural pivot is necessary: instead of maximizing semantic bandwidth per discrete token, the focus shifts to maximizing *contextual depth* per continuous state variable. This approach, which defines reasoning as an optimization process within a continuous semantic space (akin to the CoT-Space framework 7), offers a pathway to lower memory usage and higher efficiency by bypassing the computational cost associated with extensive discrete sequence processing.3

## **III. Architectural Foundation: The Continuous State Module (CSM)**

To host the proposed internal, constantly functioning reasoning engine, the CRSM selects the Continuous State Module (CSM), derived from State Space Models (SSMs), as its foundational backbone.

### **A. State Space Models (SSMs) and Dynamic Systems as a Biological Analog**

State Space Models were originally developed to predict the next state of continuous systems, such as electrical signals or the trajectory of moving objects.8 This continuous-time modeling naturally aligns with the user's requirement for an AI system that is "always functioning and working" and capable of modeling the complex learning mechanisms found in the mammalian brain.9

The Mamba architecture, derived from Selective SSMs, represents a significant advancement in this domain. Mamba rivals the efficacy of Transformer models in language modeling tasks.8 Crucially, Mamba provides an efficient, hardware-aware design that scales linearly ($O(N)$) with sequence length, overcoming the inherent quadratic complexity of standard attention mechanisms.10 This low-latency foundation is critical for enabling the internal reasoning module without incurring significant delays in output generation.

### **B. Modeling the Latent State $h(t)$: Mechanism for Context Compression and Memory**

The core of any SSM is defined by the state equation and the output equation. The state equation, represented in continuous time as $h' ( t ) \= A \* h ( t ) \+ B \* x ( t )$, describes how the system's latent state $h(t)$ changes based on the previous state and the current input $x(t)$.8

The latent state $h(t)$ is analogous to the hidden state found in Recurrent Neural Networks (RNNs) and serves as the model’s continuous memory.8 In the context of language modeling, this state effectively represents the context of a text sequence, performing a function equivalent to the KV cache in a Transformer model.8 The Mamba architecture's key innovation is its Selection Mechanism, which dynamically and selectively compresses relevant information into the state $h(t)$ while ignoring noise.11 This selectivity ensures the state representation is simultaneously efficient (compressed) yet highly effective for context-dependent reasoning, providing the architectural trade-off that yields low memory usage and high computational efficiency.11

### **C. CRSM's State Equation: Selective and Adaptive Recurrence**

The CRSM utilizes a discretized SSM, often achieved through methods like Zero Order Hold (ZOH), to function effectively for sequence-to-sequence tasks: $h	extbackslash{t} \= \\bar{A}h	extbackslash{t-1} \+ \\bar{B}x	extbackslash{t}$.8 This continuous nature establishes the fundamental "thinking module." Unlike Transformers, which are passive and must re-read context upon activation, the SSM state $h(t)$ is perpetually updating or retaining a compressed contextual memory 8, which is a necessary prerequisite for achieving true low-latency and proactive autonomy.12

The output equation, $y(t) \= C \* h(t) \+ D \* x(t)$, reveals the direct architectural hook for integrating the internal reasoning component.8 It shows that the continuous state $h(t)$ directly influences the prediction of the output $y(t)$. To implement deliberation, the CRSM must treat the SSM parameters (the A, B, C, and D matrices) not as fixed constants but as learnable weights that can be further modulated by the output of the deliberation module.8 Research already explores incorporating adaptive gating mechanisms and domain-specific statistics to refine the state-update process.13 The CRSM must leverage this, allowing the external planning signals to dynamically adjust the state matrices, effectively changing its 'memory' (A matrix) and 'input influence' (B matrix) based on strategic necessity. This transformation allows the CRSM to operate as a highly adaptable dynamical system that can dynamically shift its reasoning strategy based on task complexity, mirroring mechanisms studied in brain-inspired learning.9

Table: Comparative Analysis of Architectural Paradigms

| Feature | Transformer/GPT (Autoregressive) | Mamba/SSM (Continuous Recurrence) | CRSM (Proposed Hybrid) |
| :---- | :---- | :---- | :---- |
| **Core Operation** | Discrete prediction via Attention and Softmax | Continuous state update and selective recurrence | Continuous state + Asynchronous Deliberative Search |
| **Internal State $h(t)$ Analogue** | KV Cache (Requires reading all past tokens) | Compressed Latent State (Dynamically focused) 11 | Latent State Conditioned by MCTS Planning 13 |
| **Sequence Scaling** | Quadratic ($O(N^2)$) or Approximated Linear | Linear ($O(N)$) 10 | Linear (Base SSM) + $O(K \cdot \log N)$ (MCTS overhead) |
| **Reasoning Latency** | High (Sequential dependence) 3 | Low (Efficient recurrence) | Low (Asynchronous planning/Real-time read-out) 15 |
| **Planning Capability** | Limited ("Clever Hans" bias) 1 | Improved (Dynamic systems modeling) | Advanced (Lookahead & self-correction) 16 |

## **IV. The Internal Reasoning Component: Deliberative Architecture**

The core innovation of the CRSM lies in injecting explicit, structured planning capability directly into the continuous SSM backbone, thereby ensuring high-quality reasoning with minimal output latency.

### **A. Integrating Structured Search Algorithms into the CSM**

The fundamental deficit of autoregressive models—the inability to perform lookahead planning 2—requires an architectural fix. The proposed solution is to implement the "thinking module" as a structured search algorithm, framing reasoning problems as an exploration through a state space where each intermediate "thought" represents a node or partial solution.16

Monte Carlo Tree Search (MCTS) is an ideal candidate, acting as a "cortical planner".14 MCTS allows the model to explore multiple reasoning paths (branches) before committing to an output sequence.17 This process uses common sense reasoning and heuristics to evaluate the potential of each thought, pruning unpromising branches and dynamically balancing exploration and exploitation.16 By introducing MCTS, the CRSM explicitly addresses the sequential planning deficit by incorporating a parallel search mechanism that guides the sequential token generation process.

### **B. The Deliberation Loop: Asynchronous Planning and Internal Feedback**

The internal reasoning must function asynchronously to effectively decouple reasoning depth from output latency. The MCTS search process should generate a "Continuous Stream of reasoning steps" that runs in parallel with the SSM's token generation.15 This ensures that while the model is executing a computationally intensive, deep planning process (multiple MCTS iterations), the user can still receive an immediate, high-confidence token output based on the rapidly evolving continuous state $h(t)$.

Crucially, the deliberation loop must be introspective, incorporating internal feedback mechanisms.18 By analyzing the utility of previous actions (e.g., "Did action A yield the expected reward?") and performing introspective node expansion—analyzing parent and sibling nodes in the search tree—the model continuously improves node quality and corrects errors, reducing catastrophic failures in complex tasks.14 The coupling of the low-latency SSM core with an asynchronous MCTS loop allows the system to reserve computational resources for deep planning while maintaining high responsiveness, which is essential for interactive and real-time systems.

### **C. Mapping Continuous State $h(t)$ to Discrete Reasoning Nodes**

A significant engineering challenge is linking the highly compressed, continuous SSM state $h(t)$ with the discrete nodes (thoughts) necessary for MCTS or Tree-of-Thoughts (ToT) search.16 This continuous-to-discrete bridge is established using advanced latent training techniques.

Latent-SFT provides a mechanism where discrete latent tokens are induced to represent compressed chunks of reasoning trace—for example, replacing 16 consecutive textual Chain-of-Thought (CoT) tokens with a single discrete latent token.19 These latent tokens then serve as the discrete nodes that the MCTS algorithm manipulates during its search. The continuous SSM state $h(t)$ is trained to generate these discrete latent tokens autonomously, thereby ensuring that $h(t)$ is not merely a passive context vector, but an active representation of the ongoing reasoning process, ready to be read and influenced by the MCTS module.

### **D. Managing Computational Overhead and Preventing Recursion Hazards**

While introspective search capabilities are beneficial for decision-making, they introduce additional resource requirements that can limit scalability.18 The CRSM minimizes this risk by leveraging the inherent efficiency of the Mamba-based SSM backbone.10 This low-latency foundation reserves cycles that are then allocated to the deliberative search component. To prevent hazards such as unchecked recursion, which risks computational loops 14, the MCTS search must be managed by a Tree of Thoughts Controller. This controller is responsible for state evaluation, applying heuristics, pruning unpromising branches, and governing the search depth (e.g., setting a max_loops feature).17

## **V. Training Blueprint: Distillation for Strategic Reasoning (SLM Focus)**

The development of a Small Language Model (SLM) proof-of-concept (POC) for the CRSM is crucial for validating efficiency and demonstrating low resource requirements.22 The training curriculum must focus on teaching genuine strategic reasoning rather than merely transferring superficial behavior.

### **A. Curriculum Design for the Small Language Model (SLM) Proof-of-Concept**

The objective for the SLM POC is to create a model that excels at reasoning by decomposing problems step-by-step, thereby enhancing observability and explainability.23 Past distillation methods relying only on external signals often lead to SLMs becoming overly confident with limited supervision.24 Therefore, the CRSM training requires methods that incorporate self-iterative feedback, such as combining knowledge distillation with Odds Ratio Preference Optimization (ORPO) 24, to ensure robustness and consistency in the reasoning process.

### **B. Advanced Knowledge Distillation: Transferring Reasoning Traces**

The core training methodology utilizes knowledge distillation to transfer the step-by-step Chain-of-Thought (CoT) reasoning capacity from a powerful LLM to the smaller CRSM backbone.22 The success of this process hinges on generating meticulous and highly nuanced training data designed to elicit strategic reasoning patterns.23 This process teaches the SLM to employ diverse solution strategies for different tasks, ensuring the model can recognize and execute the most effective approach for a specific problem.

### **C. Prompt Erasure and Self-Supervision: Cultivating Cautious Reasoning Strategy**

To move beyond naive imitation, the CRSM training blueprint incorporates the Prompt Erasure technique.23 During this phase, the SLM is presented with the intricate task and the LLM's detailed output (the strategic reasoning trace), but the original input prompt is deliberately erased.

This methodological choice forces the SLM to deduce the underlying task structure and strategic approach solely from the solution trace itself, rather than simply matching the LLM's output to the initial prompt.23 This process cultivates a "Cautious Reasoner" that learns higher-level strategizing rather than passively imitating responses. This specialized form of distillation ensures that the continuous state $h(t)$ is filled with strategic, actionable information, acting as an architectural optimization focused on planning capability.

### **D. Optimizing in Continuous Space: Bridging Semantic Embeddings and Discrete Tokens**

The final critical training step is the explicit alignment of the continuous SSM state $h(t)$ with the discrete token vocabulary, leveraging the Latent-SFT framework.20 This involves two main phases:

1. **Induction Supervision:** Generating the discrete latent tokens that compress the reasoning (CoT) sequence.19  
2. **Training Autonomy:** Training the CRSM to autonomously generate these induced latent tokens, ensuring the model can transition smoothly between continuous reasoning and discrete action. This is achieved using a weighted combination of KL loss (for continuous embedding alignment) and Cross-Entropy loss (for discrete token prediction).20

The theoretical basis for this approach stems from recasting LLM reasoning from a discrete prediction task to an optimization process within a continuous, reasoning-level semantic space.7 By providing explicit supervision for generating latent tokens that encode complex thought steps, the training guarantees that $h(t)$ converges to a meaningful, interpretable representation of the ongoing internal planning, ready to be read out by the MCTS module.

Table: Blueprint for SLM Strategic Reasoning Distillation

| Phase | Objective | Source Data / Model | Key Training Technique |
| :---- | :---- | :---- | :---- |
| **P-1: Foundational Transfer** | Baseline reasoning capability and syntax acquisition. | Public text corpora + LLM-generated CoT traces. | Supervised Fine-Tuning (SFT) + Knowledge Distillation (Logit Matching).22 |
| **P-2: Strategic Deliberation** | Teach the SLM *how* to approach complex problems and strategize. | LLM-generated reasoning traces with **Prompt Erasure**.23 | Policy Optimization (e.g., ORPO) focused on rewarding strategy diversity.24 |
| **P-3: Latent State Alignment** | Bind the continuous SSM state $h(t)$ to the discrete planning logic. | LLM-generated latent tokens that compress reasoning traces.19 | Latent-SFT, utilizing KL loss and Cross-Entropy loss on discrete/continuous alignment.20 |

## **VI. Engineering for Proactive Autonomy**

The ultimate objective—enabling the model to function autonomously, initiating action without explicit user input—is achieved by leveraging the always-on continuous internal state $h(t)$ within a deliberative agent framework.

### **A. The CRSM within the Perception-Decision-Action (P-D-A) Loop**

Autonomous AI agents operate using a complex, deliberative loop: they perceive the environment, update their internal state, deliberate (plan and reason), and then act.26 The CRSM serves as the Central Processing Unit for this loop.12 Utilizing hierarchical control structures, the CRSM’s internal deliberation component breaks down high-level, inferred goals into manageable sub-goals and action sequences, allowing for sophisticated behavior management.26

### **B. Real-Time Environment Monitoring and the Continuous State Update Mechanism**

To be proactive, the system must constantly observe the environment, infer user intent, and detect opportunities for intervention.12 This necessitates processing continuous data streams, such as real-time sensor readings or egocentric video streams.12

The SSM’s state equation allows $h(t)$ to continuously monitor the state of the environment and the objectives in real-time.8 This mechanism operates asynchronously and is event-driven, responding to data "spikes".28 This architecture contrasts sharply with typical synchronous circuits that run based on clock signals, consuming resources even when no data is being processed.28 By adopting the Adaptive State-Space Mamba concept, the CRSM can integrate domain-specific statistics (e.g., sensor reading averages) to refine the continuous state $h(t)$ dynamically.13 This continuous state $h(t)$ effectively becomes the architectural representation of "guessing the user's thoughts" and "considering the user's needs".12

### **C. Proactive Intervention Logic: Generating Output Without Explicit Prompts**

The CRSM achieves the Alpha-Service paradigm of proactive assistance 12 by establishing internal state thresholds. The continuous latent state $h(t)$, which is constantly informed by perception and asynchronous deliberation, serves as the definitive metric for detecting a "service opportunity."

When $h(t)$ reaches a predefined confidence level concerning a task requirement, a service opportunity, or a safety risk, it actively triggers the SSM’s output equation.27 For example, in autonomous control systems, if $h(t)$ determines that further execution of a maneuver is too risky, it immediately flips an internal signal (a no-go output) to force an action.27 This demonstrates that continuous state monitoring provides the necessary architectural mechanism for non-prompt-based intervention. Because the SSM backbone ensures low-latency generation 10, the resulting proactive response is immediate, transforming the interaction from a passive user experience into a collaborative dialogue that builds trust.15

Table: CRSM Framework for Proactive Intervention (P-D-A Loop)

| Loop Stage | CRSM Component | Function | Trigger Mechanism |
| :---- | :---- | :---- | :---- |
| **Perception (P)** | Neuromorphic Sensing Module / SSM Input $x(t)$ | Continuous assimilation of environment/user data streams (event-driven spikes).12 | External sensor input/environmental feedback.29 |
| **Internal State Update (D)** | CSM State Equation $h(t)$ | Continuously models context, infers intent, updates risk/opportunity metrics.8 | Real-time modulation of state matrices based on external signals.13 |
| **Deliberation (D)** | MCTS/ToT Planner | Asynchronously explores action sequences and evaluates potential outcomes (lookahead).16 | Triggered when $h(t)$ detects a high-priority service opportunity or task requirement.12 |
| **Action (A)** | SSM Output Equation $y(t)$ | Generates discrete tokens (speech/action signals) based on the latest continuous state $h(t)$.8 | $h(t)$ crosses a confidence threshold (e.g., "ready to speak," "no-go signal").27 |

## **VII. Development Roadmap and Open-Source Strategy**

To ensure the CRSM establishes itself as the next SOTA open-source model, the development plan must focus on permissive licensing, strategic benchmarking, and resource-efficient training.

### **A. Benchmarking the CRSM against SOTA Transformer and Mamba Baselines**

Benchmarking must move beyond standard language modeling metrics to explicitly evaluate the capabilities where the CRSM is designed to excel: low-latency reasoning and compositional tasks. Required evaluations should include:

* **Latency and Efficiency:** Direct comparison of inference speed and memory consumption against advanced Transformer (KV cache) and Mamba architectures.3  
* **Strategic Reasoning:** Performance metrics that test complex, multi-step planning, such as SWE-bench (code generation/debugging) and LiveCodeBench.30 These tests are necessary to quantify the CRSM's superiority in planning tasks that would otherwise expose the structural weakness of the next-token prediction paradigm.1

### **B. Licensing Considerations for Commercial and Open-Source Viability**

For maximum open-source adoption, commercial viability, and community contribution, the CRSM must utilize a highly permissive license. While some open-source models restrict commercial use or require approval 31, the recommended approach is the MIT License or Apache 2.0. The MIT License specifically grants broad rights to use, copy, modify, merge, publish, and sell the software without restriction, provided the copyright notice is included.32 This transparency is essential, as it allows the research community to examine and verify the function of the internal MCTS deliberation loop and the state alignment mechanisms, ensuring that the model is genuinely performing structured planning over opaque memorization.5

### **C. Computational Requirements for Fine-Tuning and Inference**

By focusing on an SLM architecture built on Mamba, the CRSM inherently mitigates the massive computational demands associated with training state-of-the-art LLMs, addressing significant environmental and economic concerns.4 The Mamba architecture's linear scaling 10 combined with targeted knowledge distillation 25 minimizes the overall computational requirements for fine-tuning.

The primary resource expenditure will involve the initial data generation phase: securing access to powerful commercial LLM APIs (e.g., GPT-5, Gemini, Claude) 30 to generate the sophisticated, strategic reasoning traces needed for the Prompt Erasure training methodology.23 By proving the effectiveness of the SLM POC, the CRSM establishes a new scaling trajectory that prioritizes scaling the *depth of deliberation* (MCTS complexity) and the *fidelity of the continuous state* $h(t)$ over simply increasing raw parameter count, thus bypassing the current computational bottleneck of large-scale models.4

## **VIII. Conclusion**

The analysis confirms that the limitations observed in current SOTA LLMs, specifically concerning latency and deep reasoning, are rooted in the fundamental incompatibility between the autoregressive next-token prediction objective and the requirements of genuine lookahead planning. Incremental scaling of the Transformer architecture cannot resolve the "Clever Hans" planning deficit.

The Continuous Reasoning State Model (CRSM) provides a necessary architectural pivot. By selecting the Mamba-based Continuous State Module (CSM) as its foundation, the CRSM ensures high computational efficiency and an "always-on" continuous latent state $h(t)$. By integrating an asynchronous MCTS/ToT Deliberation Loop, the CRSM introduces explicit lookahead planning that runs in parallel. This hybrid design allows the deliberation output to modulate the continuous state $h(t)$, directly biasing the sequential token generation toward strategic solutions with minimal latency impact.

The successful implementation of the SLM Proof-of-Concept, utilizing advanced distillation techniques like Prompt Erasure and Latent-SFT, will demonstrate that superior strategic capability can be achieved through architectural specialization rather than brute-force scaling. Furthermore, the continuous and event-driven nature of the SSM state $h(t)$ serves as the intrinsic mechanism for proactive autonomy, allowing the model to monitor the environment and trigger actions without explicit prompts. The CRSM thus offers a viable open-source blueprint for developing the next generation of SOTA AI that is efficient, strategically capable, and genuinely autonomous.

#### **Works cited**

1. [Literature Review] The pitfalls of next-token prediction, accessed November 10, 2025, [https://www.themoonlight.io/en/review/the-pitfalls-of-next-token-prediction](https://www.themoonlight.io/en/review/the-pitfalls-of-next-token-prediction)  
2. The Pitfalls of Next-Token Prediction - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2403.06963v3](https://arxiv.org/html/2403.06963v3)  
3. Latent Reasoning in AI: The Future of Scalable Problem-Solving - Ajith's AI Pulse, accessed November 10, 2025, [https://ajithp.com/2025/02/14/latent-reasoning-the-next-evolution-in-ai-for-scalable-adaptive-and-efficient-problem-solving/](https://ajithp.com/2025/02/14/latent-reasoning-the-next-evolution-in-ai-for-scalable-adaptive-and-efficient-problem-solving/)  
4. Continuous Autoregressive Language Models - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2510.27688v1](https://arxiv.org/html/2510.27688v1)  
5. How does Transformer Learn Implicit Reasoning? - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2505.23653v1](https://arxiv.org/html/2505.23653v1)  
6. Learning dynamical systems from data: An introduction to physics-guided deep learning | PNAS, accessed November 10, 2025, [https://www.pnas.org/doi/10.1073/pnas.2311808121](https://www.pnas.org/doi/10.1073/pnas.2311808121)  
7. Daily Papers - Hugging Face, accessed November 10, 2025, [https://huggingface.co/papers?q=discrete%20token%20prediction](https://huggingface.co/papers?q=discrete+token+prediction)  
8. What Is A Mamba Model? | IBM, accessed November 10, 2025, [https://www.ibm.com/think/topics/mamba-model](https://www.ibm.com/think/topics/mamba-model)  
9. Brain Inspired Learning of Dynamical Systems - Drexel Research Discovery, accessed November 10, 2025, [https://researchdiscovery.drexel.edu/esploro/outputs/doctoral/Brain-Inspired-Learning-of-Dynamical-Systems/991021901610304721](https://researchdiscovery.drexel.edu/esploro/outputs/doctoral/Brain-Inspired-Learning-of-Dynamical-Systems/991021901610304721)  
10. state-spaces/mamba: Mamba SSM architecture - GitHub, accessed November 10, 2025, [https://github.com/state-spaces/mamba](https://github.com/state-spaces/mamba)  
11. Mamba Explained - The Gradient, accessed November 10, 2025, [https://thegradient.pub/mamba-explained/](https://thegradient.pub/mamba-explained/)  
12. AI for Service: Proactive Assistance with AI Glasses - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2510.14359v1](https://arxiv.org/html/2510.14359v1)  
13. Adaptive State-Space Mamba for Real-Time Sensor Data Anomaly Detection - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2503.22743v1](https://arxiv.org/html/2503.22743v1)  
14. (PDF) Structured Flexibility Consciousness Model: A Brain-Inspired MCTS-Transformer Framework for Multimodal Reasoning - ResearchGate, accessed November 10, 2025, [https://www.researchgate.net/publication/388820131_Structured_Flexibility_Consciousness_Model_A_Brain-Inspired_MCTS-Transformer_Framework_for_Multimodal_Reasoning](https://www.researchgate.net/publication/388820131_Structured_Flexibility_Consciousness_Model_A_Brain-Inspired_MCTS-Transformer_Framework_for_Multimodal_Reasoning)  
15. AsyncVoice Agent: Real-Time Explanation for LLM Planning and Reasoning - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2510.16156v1](https://arxiv.org/html/2510.16156v1)  
16. Evaluation of LLM : From Transformer to Reasoning model | by Pratik - Medium, accessed November 10, 2025, [https://medium.com/@pratik.vyas_10544/evaluation-of-llm-from-transformer-to-reasoning-model-a7cce84f8685](https://medium.com/@pratik.vyas_10544/evaluation-of-llm-from-transformer-to-reasoning-model-a7cce84f8685)  
17. What is Tree Of Thoughts Prompting? - IBM, accessed November 10, 2025, [https://www.ibm.com/think/topics/tree-of-thoughts](https://www.ibm.com/think/topics/tree-of-thoughts)  
18. I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2502.14693v1](https://arxiv.org/html/2502.14693v1)  
19. Mixing Latent and Text Tokens for Improved Language Model Reasoning - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2502.03275v1](https://arxiv.org/html/2502.03275v1)  
20. Latent Reasoning in LLMs as a Vocabulary-Space Superposition - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2510.15522v1](https://arxiv.org/html/2510.15522v1)  
21. kyegomez/tree-of-thoughts: Plug in and Play Implementation of Tree of Thoughts: Deliberate Problem Solving with Large Language Models that Elevates Model Reasoning by atleast 70% - GitHub, accessed November 10, 2025, [https://github.com/kyegomez/tree-of-thoughts](https://github.com/kyegomez/tree-of-thoughts)  
22. [2402.04616] Beyond Answers: Transferring Reasoning Capabilities to Smaller LLMs Using Multi-Teacher Knowledge Distillation - arXiv, accessed November 10, 2025, [https://arxiv.org/abs/2402.04616](https://arxiv.org/abs/2402.04616)  
23. LLMs Training SLMs - Kore.ai, accessed November 10, 2025, [https://www.kore.ai/blog/llms-training-slms](https://www.kore.ai/blog/llms-training-slms)  
24. Learning to Reason via Self-Iterative Process Feedback for Small Language Models - arXiv, accessed November 10, 2025, [https://arxiv.org/abs/2412.08393](https://arxiv.org/abs/2412.08393)  
25. Distilling Reasoning Capabilities into Smaller Language Models - ACL Anthology, accessed November 10, 2025, [https://aclanthology.org/2023.findings-acl.441/](https://aclanthology.org/2023.findings-acl.441/)  
26. Reactive and Deliberative AI agents - Vikas Goyal, accessed November 10, 2025, [https://vikasgoyal.github.io/agentic/reactivedeliberativeagents.html](https://vikasgoyal.github.io/agentic/reactivedeliberativeagents.html)  
27. Neuro-LIFT: A Neuromorphic, LLM-based Interactive Framework for Autonomous Drone FlighT at the Edge - arXiv, accessed November 10, 2025, [https://arxiv.org/html/2501.19259v1](https://arxiv.org/html/2501.19259v1)  
28. How neuromorphic computing takes inspiration from our brains - IBM Research, accessed November 10, 2025, [https://research.ibm.com/blog/what-is-neuromorphic-or-brain-inspired-computing](https://research.ibm.com/blog/what-is-neuromorphic-or-brain-inspired-computing)  
29. Inner Monologue: Embodied Reasoning through Planning with Language Models. Robotics at Google., accessed November 10, 2025, [https://innermonologue.github.io/](https://innermonologue.github.io/)  
30. 6 Best LLMs for Coding To Try in 2025 [Comparison List] - Zencoder, accessed November 10, 2025, [https://zencoder.ai/blog/best-llm-for-coding](https://zencoder.ai/blog/best-llm-for-coding)  
31. Top 10 open source LLMs for 2025 - Instaclustr, accessed November 10, 2025, [https://www.instaclustr.com/education/open-source-ai/top-10-open-source-llms-for-2025/](https://www.instaclustr.com/education/open-source-ai/top-10-open-source-llms-for-2025/)  
32. The MIT License - Open Source Initiative, accessed November 10, 2025, [https://opensource.org/license/mit](https://opensource.org/license/mit)