model:
  vocab_size: 1000
  d_model: 32
  d_state: 16
  d_ffn: 64
  num_layers: 2
  dropout: 0.0

reasoning:
  c_puct: 1.0
  n_simulations: 2
  temperature: 1.0
  injection_rate: 0.1

training:
  batch_size: 2
  seq_len: 16
  lr: 1e-3
  backbone_epochs: 1
  finetune_epochs: 1
  finetune_lr: 1e-4
  grad_accum: 1
  use_amp: false

dynamics:
  dynamics_samples: 10
  dynamics_epochs: 1
  dynamics_lr: 1e-3

data:
  data_dir: "data/text_corpus"
  traces_path: "data/train_traces.jsonl"

tokenizer: null
seed: 42
