training:
  backbone_epochs: 10
  batch_size: 32
  seq_len: 128
  lr: 5e-4
  grad_accum: 1
  use_amp: true
  finetune_epochs: 5
  finetune_lr: 1e-5
  value_training:
    rollouts_per_prompt: 4
    epochs: 5
    lr: 1e-4

model:
  vocab_size: 50257
  d_model: 256
  d_state: 128
  d_ffn: 1024
  num_layers: 4
  dropout: 0.1

dynamics:
  dynamics_samples: 50000
  dynamics_epochs: 10
  dynamics_lr: 1e-3

reasoning:
  c_puct: 1.0
  n_simulations: 10
  max_think_steps: 5
  lookahead: 3

data:
  data_dir: "data/text_corpus"
  traces_path: "data/traces.jsonl"
  reasoning_data: "data/reasoning_tasks.jsonl"

system:
  device: "cuda"
  seed: 42
